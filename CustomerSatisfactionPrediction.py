# -*- coding: utf-8 -*-
"""ModelsShowcase1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zw_MomGuOhIwi1ANya_G1OOcfPWD5Bbu

#### Customer Satisfaction Prediction
"""

# Import packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn as sk
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
# Set display options to show all columns
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

# Load datasets
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

# View first 5 rows of train_df
train_df.head()



# Data Cleaning
# Drop Unnamed: 0 column
train_df = train_df.drop(columns=['Unnamed: 0'])
test_df = test_df.drop(columns=['Unnamed: 0'])

# Data Preprocessing
# Access rows with missing values from column
# Variable Arrival Delay in Minutes has NAN values representing no Delay
# Assign 0 to say 0 minutes of Delay
print(train_df.isna().sum(axis=0))
print(train_df.isna().sum(axis=0))

# Drop rows with missing values
train_df=train_df.dropna(axis=0)
test_df=test_df.dropna(axis=0)

# Fillna with 0
train_df['Arrival Delay in Minutes'] = train_df['Arrival Delay in Minutes'].fillna(0)
test_df['Arrival Delay in Minutes'] = test_df['Arrival Delay in Minutes'].fillna(0)

# View unique categories in categorical columns
print(train_df['Customer Type'].value_counts())
print(train_df['Type of Travel'].value_counts())
print(train_df['Class'].value_counts())

# Define a  mapping dictionary for all categorical columns
mapping = {
    'Gender': {'Male': 0, 'Female': 1},
    'satisfaction': {'satisfied': 1, 'neutral or dissatisfied': 0},
    'Customer Type':{'Loyal Customer':1,'disloyal Customer':0},
    'Type of Travel':{'Business travel':1,'Personal Travel':0},
    'Class':{'Business':2,'Eco Plus':1,'Eco':0}

}

# Loop through the columns and apply the mapping
for col, col_mapping in mapping.items():
    train_df[col] = train_df[col].map(col_mapping)
    test_df[col] = test_df[col].map(col_mapping)


# Drop id column
train_df= train_df.drop(columns='id')

test_df= test_df.drop(columns='id')

# View columns
train_df.columns


# Feature Engineering 
# Select features to scale
features_to_scale =['Age', 'Flight Distance', 'Inflight wifi service',
       'Departure/Arrival time convenient', 'Ease of Online booking',
       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',
       'Inflight entertainment', 'On-board service', 'Leg room service',
       'Baggage handling', 'Checkin service', 'Inflight service',
       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']



# Feature Selection
# All features will be taken into consideratio
scaler = StandardScaler()
# Apply Standard Scaler
scaled_train = scaler.fit_transform(train_df[features_to_scale])
scaled_test = scaler.transform(test_df[features_to_scale])

# Replace the scaled values in the train and test dataframe
train_df[features_to_scale]= scaled_train
test_df[features_to_scale]= scaled_test


# Split train and test into X Features and y Target
X_train = train_df.iloc[:, :-1]
y_train = train_df.iloc[:, -1]

X_test = test_df.iloc[:, :-1]
y_test = test_df.iloc[:, -1]

# Logistic Regression
logreg_model = LogisticRegression()
logreg_model.fit(X_train, y_train)
logreg_preds = logreg_model.predict(X_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, logreg_preds))
print(classification_report(y_test, logreg_preds))

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, rf_preds))
print(classification_report(y_test, rf_preds))

# Gradient Boosting
gb_model = GradientBoostingClassifier()
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)
print("Gradient Boosting Accuracy:", accuracy_score(y_test, gb_preds))
print(classification_report(y_test, gb_preds))

# Support Vector Machine (SVM)
svm_model = SVC()
svm_model.fit(X_train, y_train)
svm_preds = svm_model.predict(X_test)
print("SVM Accuracy:", accuracy_score(y_test, svm_preds))
print(classification_report(y_test, svm_preds))

# K-Nearest Neighbors (KNN)
knn_model = KNeighborsClassifier(n_neighbors=5)  
knn_model.fit(X_train, y_train)
knn_preds = knn_model.predict(X_test)
print("KNN Accuracy:", accuracy_score(y_test, knn_preds))
print(classification_report(y_test, knn_preds))

# Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
nb_preds = nb_model.predict(X_test)
print("Naive Bayes Accuracy:", accuracy_score(y_test, nb_preds))
print(classification_report(y_test, nb_preds))

